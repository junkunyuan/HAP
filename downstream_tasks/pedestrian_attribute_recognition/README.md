# Pedestrian Attribute Recognition

## ğŸ“š Contents
- [Pedestrian Attribute Recognition](#pedestrian-attribute-recognition)
  - [ğŸ“š Contents](#-contents)
  - [ğŸ“‹ Introduction](#-introduction)
  - [ğŸ“‚ Datasets](#-datasets)
  - [ğŸ› ï¸ Environment](#ï¸-environment)
  - [ğŸš€ Get Started](#-get-started)
  - [ğŸ’— Acknowledgement](#-acknowledgement)
  - [ğŸ¤ Contribute \& Contact](#-contribute--contact)

## ğŸ“‹ Introduction

The HAP pre-trained model is fine-tuned for the pedestrian attribute recognition task with respect to:

- Three datasets: PA-100K, RAP, and PETA

## ğŸ“‚ Datasets

Put the dataset directories outside the HAP project:
```bash
home
â”œâ”€â”€ HAP
â”œâ”€â”€ PA-100K  # PA-100K dataset directory
â”‚   â”œâ”€â”€ annotation.mat
â”‚   â”œâ”€â”€ dataset_all.pkl
â”‚   â””â”€â”€ data
â”‚       â”œâ”€â”€ xxx.jpg
â”‚       â””â”€â”€ ...
â”œâ”€â”€ RAP  # RAP dataset directory
â”‚   â”œâ”€â”€ RAP_annotation
â”‚   â”‚   â””â”€â”€ RAP_annotation.mat
â”‚   â”œâ”€â”€ dataset_all.pkl
â”‚   â””â”€â”€ RAP_dataset
â”‚       â”œâ”€â”€ xxx.png
â”‚       â””â”€â”€ ...     
â””â”€â”€ PETA  # PETA dataset directory
    â”œâ”€â”€ PETA.mat
    â”œâ”€â”€ dataset_all.pkl
    â””â”€â”€ images
        â”œâ”€â”€ xxx.png
        â””â”€â”€ ...
```

## ğŸ› ï¸ Environment
Conda is recommended for configuring the environment:
```bash
conda env create -f env_attribute.yaml && conda activate env_attribute

# Install mmcv
cd ../2d_pose_estimation/mmcv && git checkout v1.3.9 && MMCV_WITH_OPS=1 && cd .. && python -m pip install -e mmcv
```

## ğŸš€ Get Started

It may need 8 GPUs with memory larger than 6GB, such as NVIDIA V100, for training.

```bash
# -------------------- Fine-Tuning HAP for Pedestrian Attribute Recognition --------------------

# Download the checkpoint and move it here
CKPT=ckpt_default_pretrain_pose_mae_vit_base_patch16_LUPersonPose_399.pth

cd Rethinking_of_PAR/

DATA=pa100k  # {pa100k, rapv1, peta}

python -m torch.distributed.launch \
    --nproc_per_node=${NPROC_PER_NODE} \
    --master_port=${PORT} \
    train.py \
    --cfg configs/pedes_baseline/${DATA}.yaml
```

## ğŸ’— Acknowledgement

Our implementation is based on the codebase of [Rethinking_of_PAR
](https://github.com/valencebond/Rethinking_of_PAR).

## ğŸ¤ Contribute & Contact

Feel free to star and contribute to our repository. 

If you have any questions or advice, contact us through GitHub issues or email (yuanjk0921@outlook.com).