# 3D Pose and Shape Estimation

## ğŸ“š Contents
- [3D Pose and Shape Estimation](#3d-pose-and-shape-estimation)
  - [ğŸ“š Contents](#-contents)
  - [ğŸ“‹ Introduction](#-introduction)
  - [ğŸ“‚ Datasets](#-datasets)
  - [ğŸ› ï¸ Environment](#ï¸-environment)
  - [ğŸš€ Get Started](#-get-started)
  - [ğŸ’— Acknowledgement](#-acknowledgement)
  - [ğŸ¤ Contribute \& Contact](#-contribute--contact)

## ğŸ“‹ Introduction

The HAP pre-trained model is fine-tuned on Human3.6M, MuCo, COCO, MPII datasets and evaluated on 3DPW dataset for the 3d human pose and shape estimation task.

## ğŸ“‚ Datasets

Put the dataset directories outside the HAP project:

```bash
home
â”œâ”€â”€ HAP
â”œâ”€â”€ Human36M  # Human3.6M dataset directory
â”‚   â”œâ”€â”€ annotations
â”‚   â””â”€â”€ images
â”œâ”€â”€ MuCo  # MuCo dataset directory
â”‚   â””â”€â”€ data
â”‚       â”œâ”€â”€ augmented_set
â”‚       â”œâ”€â”€ unaugmented_set
â”‚       â”œâ”€â”€ MuCo-3DHP.json
â”‚       â””â”€â”€ smpl_param.json
â”œâ”€â”€ coco  # COCO dataset directory
â”‚   â”œâ”€â”€ annotations
â”‚   â””â”€â”€ images
â”‚       â”œâ”€â”€ train2017
â”‚       â””â”€â”€ val2017
â”œâ”€â”€ mpii  # MPII dataset directory
â”‚   â””â”€â”€ data
â”‚       â”œâ”€â”€ annotations
â”‚       â””â”€â”€ images
â””â”€â”€ PW3D  # 3DPW dataset directory
    â””â”€â”€ data
        â”œâ”€â”€ 3DPW_latest_train.json
        â”œâ”€â”€ 3DPW_latest_validation.json
        â”œâ”€â”€ 3DPW_latest_test.json
        â”œâ”€â”€ 3DPW_validation_crowd_hhrnet_result.json
        â””â”€â”€ imageFiles
```

## ğŸ› ï¸ Environment

Conda is recommended for configuring the environment:
```bash
conda env create -f env-3d_pose.yaml && conda activate env_3d_pose

cd HAP/downstream_tasks/3d_pose_estimation/3DCrowdNet_RELEASE/ && sh requirements.sh
```

Download the required files following [3DCrowdNet](https://github.com/hongsukchoi/3DCrowdNet_RELEASE).

Prepare them as well as datasets by

```bash
cd HAP/downstream_tasks/3d_pose_estimation/3DCrowdNet_RELEASE/data/

DATA_PATH=../../../../../../

# Download J_regressor_extra.npy and move it here

# ---------- Prepare Human3.6M data ----------
cd Human36M
ln -s ${DATA_PATH}Human36M/images/ && ln -s ${DATA_PATH}Human36M/annotations/
# Download J_regressor_h36m_correct.npy and move it here
cd ..

# ---------- Prepare MuCo ----------
cd  MuCo && ln -s ${DATA_PATH}MuCo/data/ && cd ..

# ---------- Prepare COCO ----------
cd MSCOCO
# Download J_regressor_coco_hip_smpl.npy and MSCOCO_train_SMPL_NeuralAnnot.json and move them here
ln -s ${DATA_PATH}coco/images/ && ln -s ${DATA_PATH}coco/annotations/
cd ..

# ---------- Prepare MPII ----------
cd MPII
mkdir data && cd data
ln -s ${DATA_PATH}../mpii/images && ln -s ${DATA_PATH}../mpii/annotations
cd annotations
# Download MPII_train_SMPL_NeuralAnnot.json and move it here
cd ../..

# ---------- Prepare PW3D ----------
cd PW3D && ln -s ${DATA_PATH}/PW3D/data && cd ..

# ---------- Prepare SMPL models ----------
cd ../common/utils/smplpytorch/smplpytorch/native/models/
# Download basicModel_neutral_lbs_10_207_0_v1.0.0.pkl, basicModel_m_lbs_10_207_0_v1.0.0.pkl, basicModel_f_lbs_10_207_0_v1.0.0.pkl, and move them here
cd -

# ---------- Prepare vposer ----------
VP_PAHT=../common/utils/human_model_files/smpl/VPOSER_CKPT/
mkdir -p ${VP_PAHT} && cd ${VP_PAHT}
# Download vposer.zip and unzip it here 
cd -

# ---------- Prepare pre-trained 2D pose model
# You may need to run the 2d pose task and get the checkpoint of latest.pth
mv latest.pth ../
```

## ğŸš€ Get Started

It may need 8 GPUs with memory larger than 32GB, such as NVIDIA A100, for training.

```bash
# -------------------- Fine-Tuning HAP for 3D Pose and Shape Estimation --------------------
cd HAP/downstream_tasks/3d_pose_estimation/3DCrowdNet_RELEASE/main/

# ---------- Training ----------
python train.py \
    --gpu 0-7 \
    --amp \
    --cfg ../assets/yaml/3dpw_vit_b_4gpu.yml

# ---------- Evaluation ----------
for((EPOCH=0; EPOCH<11; EPOCH++)); do python test.py \
   --gpu 0-7 \
   --test_epoch ${EPOCH} \
   --exp_dir ../output-3d_pose/ \
   --cfg ../assets/yaml/3dpw_vit_b_4gpu.yml \
echo 'finish test for epoch '${EPOCH} \
done
```

## ğŸ’— Acknowledgement

Our implementation is based on the codebase of [3DCrowdNet](https://github.com/hongsukchoi/3DCrowdNet_RELEASE).

## ğŸ¤ Contribute & Contact

Feel free to star and contribute to our repository. 

If you have any questions or advice, contact us through GitHub issues or email (yuanjk0921@outlook.com).
