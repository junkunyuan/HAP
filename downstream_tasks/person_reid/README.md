# Person ReID

## ğŸ“š Contents
- [Person ReID](#person-reid)
  - [ğŸ“š Contents](#-contents)
  - [ğŸ“‹ Introduction](#-introduction)
  - [ğŸ“‚ Datasets](#-datasets)
  - [ğŸ› ï¸ Environment](#ï¸-environment)
  - [ğŸš€ Get Started](#-get-started)
  - [ğŸ’— Acknowledgement](#-acknowledgement)
  - [ğŸ¤ Contribute \& Contact](#-contribute--contact)

## ğŸ“‹ Introduction

The HAP pre-trained model is fine-tuned for the conventional person ReID task with respect to:

- Two datasets: MSMT17 and Market-1501
- Two resolution sizes: (256, 128) and (384, 128)
- Two model structures: ViT and ViT-lem

## ğŸ“‚ Datasets

Put the dataset directories outside the HAP project:
```bash
home
â”œâ”€â”€ HAP
â”œâ”€â”€ msmt  # MSMT17 dataset directory
â”‚   â”œâ”€â”€ bounding_box_train
â”‚   â”‚   â”œâ”€â”€ xxx.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ bounding_box_test
â”‚   â”‚   â”œâ”€â”€ xxx.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ query
â”‚       â”œâ”€â”€ xxx.jpg
â”‚       â””â”€â”€ ...
â””â”€â”€ market  # Market-1501 dataset directory
    â”œâ”€â”€ bounding_box_train
    â”‚   â”œâ”€â”€ xxx.jpg
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ bounding_box_test
    â”‚   â”œâ”€â”€ xxx.jpg
    â”‚   â””â”€â”€ ...
    â””â”€â”€ query
        â”œâ”€â”€ xxx.jpg
        â””â”€â”€ ...
```

## ğŸ› ï¸ Environment
Conda is recommended for configuring the environment:
```bash
conda env create -f env-person_reid.yaml && conda activate env_person_reid
```

## ğŸš€ Get Started

It may need 1 GPU with memory larger than 12GB, such as NVIDIA V100, for training.

```bash
# -------------------- Fine-Tuning HAP for Person ReID --------------------
cd HAP/downstream/person_reid/

# Download the checkpoint and move it here
CKPT=ckpt_default_pretrain_pose_mae_vit_base_patch16_LUPersonPose_399.pth

GPU=0
SEED=0
TAG=default
SIZE=256  # {256, 384}
DATA=msmt  # {msmt, market}
MODEL=vit_base_patch16  # {vit_base_patch16, lem_base_patch16}
OUTPUT=output-person_reid/${TAG}/${DATA}/${MODEL}/${SIZE}/${SEED}/

python main_reid.py \
    --config_file configs/reid/${DATA}.yaml \
    --model ${MODEL} \
    --batch_size 64 \
    --resume ${CKPT} \
    --epochs 100 \
    --warmup_epochs 5 \
    --lr 8e-3 \
    --size ${SIZE} \
    --device ${GPU} \
    --seed ${SEED} \
    --output_dir ${OUTPUT}
```

## ğŸ’— Acknowledgement

Our implementation is based on the codebase of [MALE](https://github.com/YanzuoLu/MALE).

## ğŸ¤ Contribute & Contact

Feel free to star and contribute to our repository. 

If you have any questions or advice, contact us through GitHub issues or email (yuanjk0921@outlook.com).